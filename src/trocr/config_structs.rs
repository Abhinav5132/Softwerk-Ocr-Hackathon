use candle_core::{DType, op::Op};
use candle_nn::Activation;
use serde::{Deserialize, de::value};
use serde_json::Value;

#[derive(Deserialize)]
pub struct DecoderTrocr{
    pub _name_or_path: String,
    pub activation_dropout: f64,
    pub activation_function: Activation,
    pub add_cross_attention: bool,
    pub architectures: Option<Value>,
    pub attention_dropout: f64,
    pub bad_words_ids: Option<Value>,
    pub begin_suppress_tokens: Option<Value>,
    pub bos_token_id: usize,
    pub chunk_size_feed_forward: usize,
    pub classifier_dropout: f32,
    pub cross_attention_hidden_size: usize,
    pub d_model: usize,
    pub decoder_attention_heads: usize,
    pub decoder_ffn_dim: usize,
    pub decoder_layerdrop: f64,
    pub decoder_layers: usize,
    pub decoder_start_token_id: u32,
    pub diversity_penalty: f32,
    pub do_sample: bool,
    pub dropout: f64,
    pub early_stopping: bool,
    pub encoder_no_repeat_ngram_size: usize,
    pub eos_token_id: u32,
    pub exponential_decay_length_penalty: Option<Value>,
    pub finetuning_task: Option<Value>,
    pub forced_bos_token_id: Option<Value>,
    pub forced_eos_token_id: Option<Value>,
    pub id2label: Id2label,
    pub init_std: f64,
    pub is_decoder: bool,
    pub lable2id: Label2id,
    pub is_encoder_decoder: bool,
    pub layernorm_embedding: bool,
    pub length_penalty: f32,
    pub max_length: usize,
    pub max_position_embeddings: usize,
    pub min_length: usize,
    pub model_type: String,
    pub no_repeat_ngram_size: usize,
    pub num_beam_groups: usize,
    pub num_beams: usize,
    pub num_return_sequences: usize,
    pub output_attentions: bool,
    pub output_hidden_states: bool,
    pub output_scores: bool,
    pub pad_token_id: usize,
    pub prefix:Option<Value>,
    pub problem_type: Option<Value>,
    pub pruned_heads: Option<Value>,
    pub remove_invalid_values: bool,
    pub repetition_penalty: f32,
    pub return_dict: bool,
    pub return_dict_in_generate: bool,
    pub scale_embedding: bool,
    pub sep_token_id: Option<Value>,
    pub suppress_tokens: Option<Value>,
    pub task_specific_params: Option<Value>,
    pub temperature: f32,
    pub tf_legacy_loss: bool,
    pub tie_encoder_decoder: bool,
    pub tie_word_embeddings: bool,
    pub tokenizer_class: Option<Value>,
    pub top_k: usize,
    pub top_p: f32,
    pub torch_dtype: Option<Value>,
    pub torchscript: bool,
    pub typical_p: f32,
    pub use_bfloat16: bool,
    pub use_cache: bool,
    pub use_learned_position_embeddings: bool,
    pub vocab_size: usize
}

#[derive(Deserialize)]
pub struct Id2label{
    #[serde(rename = "0")]
    zero: String,
    #[serde(rename = "1")]
    one: String
}

#[derive(Deserialize)]
pub struct Label2id{

    LABEL_0: usize,
    LABEL_1: usize
}

#[derive(Deserialize)]
pub struct EncoderTrocr {
    pub _name_or_path: String,
    pub add_cross_attention: bool,
    pub architectures: Option<Value>,
    pub attention_probs_dropout_prob: f32,
    pub bad_words_ids: Option<Value>,
    pub begin_suppress_tokens: Option<Value>,
    pub bos_token_id: Option<Value>,
    pub chunk_size_feed_forward: usize,
    pub cross_attention_hidden_size: Option<Value>,
    pub decoder_start_token_id: Option<Value>,
    pub diversity_penalty: f32,
    pub do_sample: bool,
    pub early_stopping: bool,
    pub encoder_no_repeat_ngram_size: usize,
    pub encoder_stride: usize,
    pub eos_token_id: Option<Value>,
    pub exponential_decay_length_penalty: Option<Value>,
    pub finetuning_task: Option<Value>,
    pub forced_bos_token_id: Option<Value>,
    pub forced_eos_token_id: Option<Value>,
    pub hidden_act: Activation,
    pub hidden_dropout_prob: f32,
    pub hidden_size: usize,
    pub id2label: Id2label,
    pub image_size: usize,
    pub initializer_range: f32,
    pub intermediate_size: usize,
    pub is_decoder: bool,
    pub is_encoder_decoder: bool,
    pub label2id: Label2id,
    pub layer_norm_eps: f64,
    pub length_penalty: f32,
    pub max_length: usize,
    pub min_length: usize,
    pub model_type: String,
    pub no_repeat_ngram_size: usize,
    pub num_attention_heads: usize,
    pub num_beam_groups: usize,
    pub num_beams: usize,
    pub num_channels: usize,
    pub num_hidden_layers: usize,
    pub num_return_sequences: usize,
    pub output_attentions: bool,
    pub output_hidden_states: bool,
    pub output_scores: bool,
    pub pad_token_id: Option<Value>,
    pub patch_size: usize,
    pub prefix: Option<Value>,
    pub problem_type: Option<Value>,
    pub pruned_heads: Option<Value>,
    pub qkv_bias: bool,
    pub remove_invalid_values: bool,
    pub repetition_penalty: f32,
    pub return_dict: bool,
    pub return_dict_in_generate: bool,
    pub sep_token_id: Option<Value>,
    pub suppress_tokens: Option<Value>,
    pub task_specific_params: Option<Value>,
    pub temperature: f32,
    pub tf_legacy_loss: bool,
    pub tie_encoder_decoder: bool,
    pub tie_word_embeddings: bool,
    pub tokenizer_class: Option<Value>,
    pub top_k: usize,
    pub top_p: usize,
    pub torch_dtype: Option<Value>,
    pub torchscript: bool,
    pub typical_p: f32,
    pub use_bfloat16: bool,
}

#[derive(Deserialize)]
pub struct ModelConfig {
    pub _name_or_path: String,
    pub architectures: Vec<String>,
    pub decoder_start_token_id: usize,
    pub early_stopping: bool,
    pub eos_token_id: usize,
    pub is_encoder_decoder: bool,
    pub length_penalty: f32,
    pub max_length: usize,
    pub model_type: String,
    pub no_repeat_ngram_size: usize,
    pub num_beams: usize,
    pub pad_token_id: usize,
    pub tie_word_embeddings: bool,
    pub torch_dtype: String,
    pub transformers_version: String,
    pub vocab_size: usize,
    pub encoder: EncoderTrocr,
    pub decoder: DecoderTrocr
}